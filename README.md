# Twitter Scraper using Selenium
___

## About
There are 2 apps : scrapper and data cleaner.
Scrapper is used for get tweet data from twitter.
Data cleaner is used for transform tweet data to lowercase, delete all character exclude alphabets, and delete same words.

For scrapper result will be saved in `data/raw` folder.
For data cleaner result will be saved in `data/case_folding` for lowercased and deleted char exclude alphabets and `data/dictionary` folder for unique words of case_folding data files.
___
## Requirements
1. Python 3.7.9 ++
2. PIP
___
## How To Run

### Scrapper
1. Set parameters you want to get in `input.txt`, the parameters are `KEYWORD;LOCATION;START_DATE;END_DATE`. If you want to bulk scrape you can write like this:
```
FIRST_KEYWORD;FIRST_LOCATION;FIRST_START_DATE;FIRST_END_DATE
SECOND_KEYWORD;SECOND_LOCATION;SECOND_START_DATE;SECOND_END_DATE
``` 
2. Activate virtual env.
3. Run `pip install -r requirements.txt`.
4. Run `python run_selenium.py`.

### Data Cleaner
1. Make sure you have data in `data/raw`, it's the result or generated by scrapper.
2. Activate virtual env.
3. Run `pip install -r requirements.txt`.
4. Run `python cleaning_data.py`.